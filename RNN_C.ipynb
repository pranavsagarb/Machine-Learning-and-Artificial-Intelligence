{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqK4U4dRP1H7"
      },
      "source": [
        "At the end of the experiment:\n",
        "\n",
        "1.   Generate text which is similar to the writing style of William Shakespeare\n",
        "2.   Understand how to adapt or tune the trained network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rXIJFmjoBdi"
      },
      "source": [
        "###  Description\n",
        "\n",
        "The dataset used in this experiment has partial content of different plays of Shakespeare concatenated into a single plain text file. \n",
        "\n",
        "Shakespeare is a famous English poet , play writer and actor. He is regarded as the greatest writer in the English language and the world's greatest dramatist. He is often called a England's national poet and the Bard of Avon. \n",
        "\n",
        "We have chosen plays of Shakespeare as our dataset mainly for two reasons : \n",
        "\n",
        "1. His work is widely recognized as standard for poetry and language.\n",
        "2. The result of combining of his work provides a sizeable corpus for our model to learn.\n",
        "\n",
        "The plays of Shakespeare are taken from the following url:\n",
        "\n",
        "www.opensourceshakespeare.org/views/plays/plays.php\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wj_Bik_GtTml"
      },
      "source": [
        "In this experiment we will follow below steps:\n",
        "\n",
        "1.   Preparing the data\n",
        "2.   Building the model\n",
        "3.   Defining helper functions\n",
        "4.   Training the model\n",
        "5.    Adapting or Fine-tuning for text generation\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56VkvpnlvicS"
      },
      "source": [
        "Let us start by importing all the required packages to perform this experiment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11e72PpPZ6Ca"
      },
      "source": [
        "## Importing required packages\n",
        "import unidecode\n",
        "import string\n",
        "import random\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sE5njLNJZ6Cg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2d37b713-24a3-4413-b7af-f28d91101be6"
      },
      "source": [
        "all_characters = string.printable\n",
        "## code to find length of all_characters and storing the value in n_characters\n",
        "n_characters = len(all_characters)\n",
        "## code to convert unicode characters into plain ASCII.\n",
        "file = unidecode.unidecode(open('shakespeare.txt').read())\n",
        "## code to find length of the file\n",
        "file_len = len(file)\n",
        "## printing the length of the file\n",
        "print('file_len =', file_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "file_len = 1115393\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gM3NTD74Z6Cp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "ba4f6606-70b2-43a1-afb9-0ddbad66e137"
      },
      "source": [
        "file[:1000]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you know Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us kill him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be done: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citizens, the patricians good.\\nWhat authority surfeits on would relieve us: if they\\nwould yield us but the superfluity, while it were\\nwholesome, we might guess they relieved us humanely;\\nbut they think we are too dear: the leanness that\\nafflicts us, the object of our misery, is as an\\ninventory to particularise their abundance; our\\nsufferance is a gain to them Let us revenge this with\\nour pikes, ere we become rakes: for the gods know I\\nspeak this in hunger for bread, not in thirst for revenge.\\n\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TffxtFCZ6Cz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "4726e06f-ba96-452f-e2a0-4f57b4788786"
      },
      "source": [
        "## Initializing the length of chunk\n",
        "chunk_len = 200\n",
        "## Function to split the string into chunks\n",
        "def random_chunk():\n",
        "    ## Initializing the starting index value of the big string \n",
        "    start_index = random.randint(0, file_len - chunk_len)\n",
        "    ## Initializing the ending index of the string \n",
        "    end_index = start_index + chunk_len + 1\n",
        "    ## returning the chunk\n",
        "    return file[start_index:end_index]\n",
        "\n",
        "print((random_chunk()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hing-while,\n",
            "But you must trouble him with lewd complaints.\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "Brother of Gloucester, you mistake the matter.\n",
            "The king, of his own royal disposition,\n",
            "And not provoked by any suitor else;\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3h1GIrjHZ6C9"
      },
      "source": [
        "### Creating recurrent neural network\n",
        "class RNN(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
        "        super(RNN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
        "        self.rnn = nn.RNN(hidden_size, hidden_size, n_layers)\n",
        "        self.decoder = nn.Linear(hidden_size, output_size)\n",
        "    \n",
        "    def forward(self, input, hidden):\n",
        "        input = self.encoder(input.view(1, -1))\n",
        "        output, hidden = self.rnn(input.view(1, 1, -1), hidden)\n",
        "        output = self.decoder(output.view(1, -1))\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_j2hxN7QZ6DF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f123f728-51d8-4793-b245-8b624f4a773e"
      },
      "source": [
        "# Turn string into list of longs\n",
        "def char_tensor(string):\n",
        "    ## tensor is a array\n",
        "    tensor = torch.zeros(len(string)).long()\n",
        "    for c in range(len(string)):\n",
        "        tensor[c] = all_characters.index(string[c])\n",
        "    return Variable(tensor)\n",
        "\n",
        "print(char_tensor('abcDEF'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([10, 11, 12, 39, 40, 41])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siN-Z8X_Z6DN"
      },
      "source": [
        "def random_training_set():    \n",
        "    chunk = random_chunk()\n",
        "    inp = char_tensor(chunk[:-1])\n",
        "    target = char_tensor(chunk[1:])\n",
        "    return inp, target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4QPs5BqZ6DS"
      },
      "source": [
        "#### Evaluating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2m-JfwXZ6DW"
      },
      "source": [
        "def evaluate(prime_str='A', predict_len=100, temperature=0.8):\n",
        "    hidden = decoder.init_hidden()\n",
        "    prime_input = char_tensor(prime_str)\n",
        "    predicted = prime_str\n",
        "\n",
        "    # Use priming string to \"build up\" hidden state\n",
        "    for p in range(len(prime_str) - 1):\n",
        "        _, hidden = decoder(prime_input[p], hidden)\n",
        "    inp = prime_input[-1]\n",
        "    \n",
        "    for p in range(predict_len):\n",
        "        output, hidden = decoder(inp, hidden)\n",
        "        \n",
        "        # Sample from the network as a multinomial distribution\n",
        "        output_dist = output.data.view(-1).div(temperature).exp()\n",
        "        top_i = torch.multinomial(output_dist, 1)[0]\n",
        "        \n",
        "        # Add predicted character to string and use as next input\n",
        "        predicted_char = all_characters[top_i]\n",
        "        predicted += predicted_char\n",
        "        inp = char_tensor(predicted_char)\n",
        "\n",
        "    return predicted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZVmbuZ4Z6De"
      },
      "source": [
        "### 4. Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFevLn43Z6Dh"
      },
      "source": [
        "## Importing required packages\n",
        "import time, math\n",
        "## function to print amount of time passed\n",
        "def time_since(since):\n",
        "    s = time.time() - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXqylIRyZ6Dn"
      },
      "source": [
        "#### The main training function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3vWoTsxZ6Dp"
      },
      "source": [
        "def train(inp, target):\n",
        "    hidden = decoder.init_hidden()\n",
        "    decoder.zero_grad()\n",
        "    loss = 0\n",
        "\n",
        "    for c in range(chunk_len):\n",
        "        output, hidden = decoder(inp[c], hidden)\n",
        "        '''unsqueeze() is used to add dimension to the tensor'''\n",
        "        loss += criterion(output, target[c].unsqueeze(dim=0))\n",
        "    # Back propagation\n",
        "    loss.backward()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / chunk_len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPG6aUEeZ6Du",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "47d318ec-ac31-45d1-b823-a299778b3099"
      },
      "source": [
        "n_epochs = 2000 #Number of epochs\n",
        "print_every = 50\n",
        "plot_every = 20\n",
        "hidden_size = 100\n",
        "n_layers = 1\n",
        "lr = 0.005\n",
        "\n",
        "decoder = RNN(n_characters, hidden_size, n_characters, n_layers)\n",
        "## Optimizer\n",
        "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
        "## Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "start = time.time()\n",
        "all_losses = []\n",
        "loss_avg = 0\n",
        "\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    loss = train(*random_training_set())       \n",
        "    loss_avg += loss\n",
        "\n",
        "    if epoch % print_every == 0:\n",
        "        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n",
        "        print(evaluate('Wh', 100), '\\n')\n",
        "\n",
        "    if epoch % plot_every == 0:\n",
        "        all_losses.append(loss_avg / plot_every)\n",
        "        loss_avg = 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0m 4s (50 2%) 2.6452]\n",
            "Whes I lhoms nerr, wand the ure therhich ss ar, fou latd:\n",
            "Le dree:\n",
            "A:\n",
            "This freath ch le louhek, Iig, l \n",
            "\n",
            "[0m 8s (100 5%) 2.3658]\n",
            "Whe ag wee the sakos oure thoun: agce sow thest of tae iour my noter thing in the an this angedst oter \n",
            "\n",
            "[0m 13s (150 7%) 2.5844]\n",
            "Whourt.\n",
            "\n",
            "LUS:\n",
            "What that thow,\n",
            "Is ver?\n",
            "Bodow, thy wa fard of firtipt\n",
            "O, I wil speer theroundy he er cov \n",
            "\n",
            "[0m 17s (200 10%) 2.1372]\n",
            "Why, whost bomqus by theal afle onted oure sord hat thav arouth that you theage shongmeall woul amace  \n",
            "\n",
            "[0m 22s (250 12%) 2.0028]\n",
            "Whoubllass beaked\n",
            "I pe nall to the trith he stre tore hare, ge low, he, thy he lall hich wesfiar,\n",
            "Ward \n",
            "\n",
            "[0m 26s (300 15%) 2.2574]\n",
            "Whan: that nov to to shere blighthe are me day haren to they my it to thy the arak,\n",
            "wran wing'd\n",
            "Foon,\n",
            " \n",
            "\n",
            "[0m 30s (350 17%) 2.2111]\n",
            "Wher it in in thou forrs.\n",
            "Titill hall sstond pagnous hang.\n",
            "\n",
            "Slors forsht hall the ther norne. wand the \n",
            "\n",
            "[0m 34s (400 20%) 2.0980]\n",
            "Whert iver, hald ther the groonous ave the cones to now, sumes, herory thar bear, and\n",
            "you be give soce \n",
            "\n",
            "[0m 39s (450 22%) 2.0003]\n",
            "Whive you, leather not you lava, in oor man loved be you me thein thihed I sook: shall in!\n",
            "Ant aglers. \n",
            "\n",
            "[0m 43s (500 25%) 1.9096]\n",
            "What and ming morrongws that the mord me;\n",
            "What thy the nath withone a knas. what cout you buther brast \n",
            "\n",
            "[0m 48s (550 27%) 1.9292]\n",
            "Whis. I ance as to that istel stome and be to being a sentort of thy Lates but my put to have sto, bet \n",
            "\n",
            "[0m 52s (600 30%) 1.9136]\n",
            "Why me the the sereest preit that evert the purjull of your brie be and sond sterome\n",
            "The knot worgheed \n",
            "\n",
            "[0m 56s (650 32%) 2.1027]\n",
            "Wham make his preas mor potent wher chenour body by sorishe noble the waring for met, chither him shou \n",
            "\n",
            "[1m 1s (700 35%) 1.9630]\n",
            "Whan's, food call's from look;\n",
            "I strisure tin thim freat retious live my in of you as tho I for the li \n",
            "\n",
            "[1m 5s (750 37%) 2.1572]\n",
            "Whe knous the why camade\n",
            "We mar this thou and thou me othige, in a me to quight; Rode my eak's his mid \n",
            "\n",
            "[1m 9s (800 40%) 1.8095]\n",
            "Where whed a commores it beir,\n",
            "That thisgef returtertep this, withes, thou ming the streing a faren wi \n",
            "\n",
            "[1m 14s (850 42%) 1.9806]\n",
            "Whing hiont in is ell iver, wor fith is a lace,\n",
            "This bese me we prish is hear'd ohe dith an being worg \n",
            "\n",
            "[1m 18s (900 45%) 1.9132]\n",
            "Wh then this; a in I and distardy, him lorming the gore be be meat.\n",
            "\n",
            "VING ROMEO:\n",
            "Lan, sirnt for I a he \n",
            "\n",
            "[1m 22s (950 47%) 2.3082]\n",
            "What the! I am dows, a wordo thim trueting noter.\n",
            "\n",
            "The esarive the sunturst. Heartingars.\n",
            "\n",
            "Prot are wi \n",
            "\n",
            "[1m 27s (1000 50%) 1.9699]\n",
            "Whard: grave hercier cortent well\n",
            "and him teave,\n",
            "Ond phents, Ence, that ogent if thou Lead in ket, not \n",
            "\n",
            "[1m 31s (1050 52%) 1.9082]\n",
            "Whe my in theme of confill truttontand.\n",
            "\n",
            "SHENVE:\n",
            "And\n",
            "Of speather hink reathed freath,\n",
            "Oldoom the dubed \n",
            "\n",
            "[1m 36s (1100 55%) 1.9228]\n",
            "Where same the sleaces this the, welk yey as that that and I wase the than thib abroast for to met I h \n",
            "\n",
            "[1m 40s (1150 57%) 1.9486]\n",
            "What wapkingeme.\n",
            "\n",
            "POLUS:\n",
            "What crom to he'll thyse\n",
            "With, that lorst Nast the so it, Kall hold tindsher  \n",
            "\n",
            "[1m 44s (1200 60%) 1.9462]\n",
            "What ploded a neve so,\n",
            "Tertence.\n",
            "\n",
            "DUCHET:\n",
            "Segone cour.\n",
            "\n",
            "GRUMIO:\n",
            "Were the neld tean that not ervare am  \n",
            "\n",
            "[1m 49s (1250 62%) 2.1386]\n",
            "Whe I\n",
            "Srow\n",
            "Of be prewt must themps ar. her real me the tand unpeeen lintion ought the growed viste,--\n",
            " \n",
            "\n",
            "[1m 53s (1300 65%) 1.9665]\n",
            "Wher's so.\n",
            "\n",
            "AUTIO:\n",
            "Full here let me sens:\n",
            "And I inder goods, thery of thy enst and the man, prien,\n",
            "Thi \n",
            "\n",
            "[1m 57s (1350 67%) 1.8417]\n",
            "When and do love hape I well of as the becven it elf you loves; en spears, our Aup and and hou hore be \n",
            "\n",
            "[2m 2s (1400 70%) 1.9078]\n",
            "What poin I afficios; the praves,\n",
            "Whinful your hay,\n",
            "The to ailser, housits: in of my and it chold bo h \n",
            "\n",
            "[2m 6s (1450 72%) 2.0925]\n",
            "Whiled thoughup nos a ballo from to the bod brated forst him thiI hit a was a ansurrionty kill, to cri \n",
            "\n",
            "[2m 10s (1500 75%) 2.0076]\n",
            "What the the sules that the way hattred to the stome that were waster, faint concile he the you to tha \n",
            "\n",
            "[2m 15s (1550 77%) 2.1233]\n",
            "Whow me mora mean, and is sent more thing not blood, here me merie! nothery horge but motet from mosel \n",
            "\n",
            "[2m 19s (1600 80%) 1.7406]\n",
            "Whander.\n",
            "Thou you soo my fallemblo bid dorse my to muste of the sear pread thou Iwire, that'd bad, the \n",
            "\n",
            "[2m 23s (1650 82%) 1.9460]\n",
            "Whoumon lits that whou was whome with to long it, my whem man most is the sen them to to this that and \n",
            "\n",
            "[2m 28s (1700 85%) 1.6888]\n",
            "What feath you mith's a hall a dwer of is be nath lidste was have the main in is hare dight not all th \n",
            "\n",
            "[2m 32s (1750 87%) 1.7192]\n",
            "Whease, should the kne: speak not shack!\n",
            "\n",
            "Preak herson:\n",
            "Lown te hathation all the here he here,\n",
            "To ale \n",
            "\n",
            "[2m 36s (1800 90%) 2.2945]\n",
            "Whor her not and my jall lord shade my my sersand!\n",
            "\n",
            "HENENIUS:\n",
            "He the prasselk intersungs.\n",
            "This sticl r \n",
            "\n",
            "[2m 41s (1850 92%) 1.7422]\n",
            "Why lore as I did sired conjurde you angman of I off hear the here more a purcess;\n",
            "To the sulser the b \n",
            "\n",
            "[2m 45s (1900 95%) 1.6872]\n",
            "What herefore thy sance, ture, fiters,\n",
            "Onter oo live thy not thee,\n",
            "But our neto his but dison of in sa \n",
            "\n",
            "[2m 49s (1950 97%) 1.9732]\n",
            "What you with speecains.\n",
            "\n",
            "CLAUDIOL:\n",
            "And you have like fardedfer, heat: most\n",
            "The king make menperself h \n",
            "\n",
            "[2m 54s (2000 100%) 1.8086]\n",
            "Whous to be they the welcalus to the dayeanes matity of caust's, first my lords,\n",
            "And a done as blome,  \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWhQGN73Z6D4"
      },
      "source": [
        "#### Plotting the Training Losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRMgqaJoZ6D8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "9fc47418-a3e8-448a-effd-7616f2be26b9"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "%matplotlib inline\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(all_losses)\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"loss\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hkcqnIlZ6EI"
      },
      "source": [
        "We can see the effects of this by adjusting the temperature argument:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSwY7UOEZ6EK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "527cc59f-0d00-4b8a-bca0-db120f906bff"
      },
      "source": [
        "print(evaluate('u', 200, temperature=0.8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ur the sour yough,\n",
            "And what nawn a toe it\n",
            "Wears,\n",
            "To And he but make with of and leabrack,\n",
            "Beptake that awake ur, and make that with to man sirk love the like make this the lord, a where be the own we i\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIjNrZNSZ6ER"
      },
      "source": [
        "Lower temperatures are less varied, choosing only the more probable outputs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MB_ntU41a74t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "55361b46-c7f7-4134-ad2d-1556b696d019"
      },
      "source": [
        "print(evaluate('Th', 200, temperature=0.2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The like the with the be the last the make the king the stalt the be a do the known the state a love the make the state, a with of the with a the lord, and the with the make the love the love the state \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80cSDcEXZ6EU"
      },
      "source": [
        "\n",
        "Higher temperatures more varied, choosing less probable outputs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXusqAsCZ6EV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "7a57b5c7-ff8e-4101-8836-dd1779a3b0d4"
      },
      "source": [
        "print(evaluate('how', 200, temperature=1.4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "howneds? Go-condcupatierple knows, no ot:\n",
            "Aptles, the lustlend oftakiak,\n",
            "A't\n",
            "Ully caste, thou\n",
            "tathan taBus-thee Hisetoqut!\n",
            "In af;\n",
            "And letoor:\n",
            "Bud dosted than throes!\n",
            "Ands jear thee-k, wrofe; che'd,\n",
            "\n",
            "TISF\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}